{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 11:31:14.648102: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/Documents/master_project/CoppeliaSim_Player_V4_1_0_Ubuntu20_04:/home/hendrik/.mujoco/mujoco200/bin\n",
      "2022-06-18 11:31:14.648124: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsv:torch.Size([16, 28])\n",
      "+---------------------------------------------------------------------------------+------------+\n",
      "|                                     Modules                                     | Parameters |\n",
      "+---------------------------------------------------------------------------------+------------+\n",
      "|     model.transformer.transformer_encoder.layers.0.self_attn.in_proj_weight     |   480000   |\n",
      "|      model.transformer.transformer_encoder.layers.0.self_attn.in_proj_bias      |    1200    |\n",
      "|     model.transformer.transformer_encoder.layers.0.self_attn.out_proj.weight    |   160000   |\n",
      "|      model.transformer.transformer_encoder.layers.0.self_attn.out_proj.bias     |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.0.linear1.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.0.linear1.bias           |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.0.linear2.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.0.linear2.bias           |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.0.norm1.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.0.norm1.bias            |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.0.norm2.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.0.norm2.bias            |    400     |\n",
      "|     model.transformer.transformer_encoder.layers.1.self_attn.in_proj_weight     |   480000   |\n",
      "|      model.transformer.transformer_encoder.layers.1.self_attn.in_proj_bias      |    1200    |\n",
      "|     model.transformer.transformer_encoder.layers.1.self_attn.out_proj.weight    |   160000   |\n",
      "|      model.transformer.transformer_encoder.layers.1.self_attn.out_proj.bias     |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.1.linear1.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.1.linear1.bias           |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.1.linear2.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.1.linear2.bias           |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.1.norm1.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.1.norm1.bias            |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.1.norm2.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.1.norm2.bias            |    400     |\n",
      "|     model.transformer.transformer_encoder.layers.2.self_attn.in_proj_weight     |   480000   |\n",
      "|      model.transformer.transformer_encoder.layers.2.self_attn.in_proj_bias      |    1200    |\n",
      "|     model.transformer.transformer_encoder.layers.2.self_attn.out_proj.weight    |   160000   |\n",
      "|      model.transformer.transformer_encoder.layers.2.self_attn.out_proj.bias     |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.2.linear1.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.2.linear1.bias           |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.2.linear2.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.2.linear2.bias           |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.2.norm1.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.2.norm1.bias            |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.2.norm2.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.2.norm2.bias            |    400     |\n",
      "|     model.transformer.transformer_encoder.layers.3.self_attn.in_proj_weight     |   480000   |\n",
      "|      model.transformer.transformer_encoder.layers.3.self_attn.in_proj_bias      |    1200    |\n",
      "|     model.transformer.transformer_encoder.layers.3.self_attn.out_proj.weight    |   160000   |\n",
      "|      model.transformer.transformer_encoder.layers.3.self_attn.out_proj.bias     |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.3.linear1.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.3.linear1.bias           |    400     |\n",
      "|          model.transformer.transformer_encoder.layers.3.linear2.weight          |   160000   |\n",
      "|           model.transformer.transformer_encoder.layers.3.linear2.bias           |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.3.norm1.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.3.norm1.bias            |    400     |\n",
      "|           model.transformer.transformer_encoder.layers.3.norm2.weight           |    400     |\n",
      "|            model.transformer.transformer_encoder.layers.3.norm2.bias            |    400     |\n",
      "|                         model.transformer.encoder.weight                        |   160000   |\n",
      "|                          model.transformer.encoder.bias                         |    400     |\n",
      "|  model.critic_transformer.transformer_encoder.layers.0.self_attn.in_proj_weight |   480000   |\n",
      "|   model.critic_transformer.transformer_encoder.layers.0.self_attn.in_proj_bias  |    1200    |\n",
      "| model.critic_transformer.transformer_encoder.layers.0.self_attn.out_proj.weight |   160000   |\n",
      "|  model.critic_transformer.transformer_encoder.layers.0.self_attn.out_proj.bias  |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.0.linear1.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.0.linear1.bias       |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.0.linear2.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.0.linear2.bias       |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.0.norm1.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.0.norm1.bias        |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.0.norm2.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.0.norm2.bias        |    400     |\n",
      "|  model.critic_transformer.transformer_encoder.layers.1.self_attn.in_proj_weight |   480000   |\n",
      "|   model.critic_transformer.transformer_encoder.layers.1.self_attn.in_proj_bias  |    1200    |\n",
      "| model.critic_transformer.transformer_encoder.layers.1.self_attn.out_proj.weight |   160000   |\n",
      "|  model.critic_transformer.transformer_encoder.layers.1.self_attn.out_proj.bias  |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.1.linear1.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.1.linear1.bias       |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.1.linear2.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.1.linear2.bias       |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.1.norm1.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.1.norm1.bias        |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.1.norm2.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.1.norm2.bias        |    400     |\n",
      "|  model.critic_transformer.transformer_encoder.layers.2.self_attn.in_proj_weight |   480000   |\n",
      "|   model.critic_transformer.transformer_encoder.layers.2.self_attn.in_proj_bias  |    1200    |\n",
      "| model.critic_transformer.transformer_encoder.layers.2.self_attn.out_proj.weight |   160000   |\n",
      "|  model.critic_transformer.transformer_encoder.layers.2.self_attn.out_proj.bias  |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.2.linear1.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.2.linear1.bias       |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.2.linear2.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.2.linear2.bias       |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.2.norm1.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.2.norm1.bias        |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.2.norm2.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.2.norm2.bias        |    400     |\n",
      "|  model.critic_transformer.transformer_encoder.layers.3.self_attn.in_proj_weight |   480000   |\n",
      "|   model.critic_transformer.transformer_encoder.layers.3.self_attn.in_proj_bias  |    1200    |\n",
      "| model.critic_transformer.transformer_encoder.layers.3.self_attn.out_proj.weight |   160000   |\n",
      "|  model.critic_transformer.transformer_encoder.layers.3.self_attn.out_proj.bias  |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.3.linear1.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.3.linear1.bias       |    400     |\n",
      "|       model.critic_transformer.transformer_encoder.layers.3.linear2.weight      |   160000   |\n",
      "|        model.critic_transformer.transformer_encoder.layers.3.linear2.bias       |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.3.norm1.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.3.norm1.bias        |    400     |\n",
      "|        model.critic_transformer.transformer_encoder.layers.3.norm2.weight       |    400     |\n",
      "|         model.critic_transformer.transformer_encoder.layers.3.norm2.bias        |    400     |\n",
      "|                     model.critic_transformer.encoder.weight                     |   160000   |\n",
      "|                      model.critic_transformer.encoder.bias                      |    400     |\n",
      "+---------------------------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 8032800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8032800"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.dataset import HERDataset\n",
    "from model_src.model_setup import model_setup\n",
    "from utils.tensorboard import TBoardGraphs\n",
    "import hashids\n",
    "import time\n",
    "from model_src.network import Network\n",
    "import torch\n",
    "from utils.simulation import HERSimulation\n",
    "from prettytable import PrettyTable\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "hid = hashids.Hashids()\n",
    "logname = hid.encode(int(time.time() * 1000000))\n",
    "data_path = '/home/hendrik/Documents/master_project/LokalData/'\n",
    "tboard = TBoardGraphs(logname=logname, data_path=data_path)\n",
    "\n",
    "train_data = HERDataset(path='/home/hendrik/Documents/master_project/Code/MasterProject/data_fetch_random_100.npz', device='cuda', num_ele=-0)\n",
    "val_data = copy.deepcopy(train_data)\n",
    "\n",
    "model_setup['seq_len'] = 53\n",
    "model_setup['decoder']['d_output'] = 29\n",
    "#model_setup['transformer']['d_output']=4\n",
    "model_setup['transformer']['d_inpt'] = 400\n",
    "new_model_setup = model_setup\n",
    "datasets = {'train':train_data, 'val':val_data}\n",
    "model_lr = 6e-5\n",
    "critic_lr = 6e-5\n",
    "batch_size = 32\n",
    "\n",
    "simulation = HERSimulation()\n",
    "\n",
    "network = Network(model_setup=model_setup, data_sets=datasets, model_lr=model_lr, critic_lr=critic_lr, batchsize=16, tboard=tboard, simulation=simulation, batch_size=batch_size)\n",
    "count_parameters(network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len succ: 100\n",
      "len fail: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9114452600479126\n",
      "best after: -0.7258027791976929\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7345578670501709\n",
      "best after: -0.543267011642456\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8512252569198608\n",
      "best after: -0.6697025895118713\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7706927061080933\n",
      "best after: -0.5840973258018494\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7095411419868469\n",
      "best after: -0.5188436508178711\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8512586355209351\n",
      "best after: -0.6611818671226501\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9389396905899048\n",
      "best after: -0.7517039775848389\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7972400784492493\n",
      "best after: -0.6103989481925964\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8542383313179016\n",
      "best after: -0.670781135559082\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7951034903526306\n",
      "best after: -0.6084011793136597\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9386749267578125\n",
      "best after: -0.7453345656394958\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.6868430972099304\n",
      "best after: -0.4995914101600647\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8946760296821594\n",
      "best after: -0.7017012238502502\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -1.0098565816879272\n",
      "best after: -0.8219361305236816\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7771853804588318\n",
      "best after: -0.5855156779289246\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7714412808418274\n",
      "best after: -0.582144558429718\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8918507099151611\n",
      "best after: -0.7005468606948853\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9368666410446167\n",
      "best after: -0.7442593574523926\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.970659613609314\n",
      "best after: -0.787634015083313\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9635056257247925\n",
      "best after: -0.7776177525520325\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7792247533798218\n",
      "best after: -0.5922589302062988\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9886797666549683\n",
      "best after: -0.8011963963508606\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7904753088951111\n",
      "best after: -0.6052244305610657\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7283692359924316\n",
      "best after: -0.5383574962615967\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8624011874198914\n",
      "best after: -0.6747964024543762\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.6444668173789978\n",
      "best after: -0.4496188163757324\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.6681907773017883\n",
      "best after: -0.4756181836128235\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.7693841457366943\n",
      "best after: -0.5840394496917725\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8282769322395325\n",
      "best after: -0.6434066891670227\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.9184675216674805\n",
      "best after: -0.7277430295944214\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8332005143165588\n",
      "best after: -0.6521064043045044\n",
      "__________________________________________________----\n",
      "shapes:\n",
      "torch.Size([25])\n",
      "torch.Size([3])\n",
      "torch.Size([1, 28])\n",
      "best before: -0.8282150030136108\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hendrik/Documents/master_project/Code/MasterProject/her.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hendrik/Documents/master_project/Code/MasterProject/her.ipynb#ch0000001?line=0'>1</a>\u001b[0m network\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m100000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/MasterProject/model_src/network.py:77\u001b[0m, in \u001b[0;36mNetwork.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate()\n\u001b[1;32m     <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=75'>76</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_mode(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimulate(num_envs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, prefix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39moptimisation \u001b[39;49m\u001b[39m'\u001b[39;49m, add_data\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=77'>78</a>\u001b[0m \u001b[39mif\u001b[39;00m (epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m%\u001b[39m\u001b[39m1\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=78'>79</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_mode(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/MasterProject/model_src/network.py:196\u001b[0m, in \u001b[0;36mNetwork.simulate\u001b[0;34m(self, num_envs, prefix, add_data, device)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=193'>194</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m gt_policy_success:\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=194'>195</a>\u001b[0m     seeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimulation\u001b[39m.\u001b[39mget_seeds(n\u001b[39m=\u001b[39mnum_envs)\n\u001b[0;32m--> <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=195'>196</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimulation\u001b[39m.\u001b[39;49msimulate(policy \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, seeds\u001b[39m=\u001b[39;49mseeds, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=196'>197</a>\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/network.py?line=197'>198</a>\u001b[0m         trajectories, inpt_obs, labels, success, critic_scores \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/Documents/master_project/Code/MasterProject/utils/simulation.py:99\u001b[0m, in \u001b[0;36mHERSimulation.simulate\u001b[0;34m(self, policy, seeds, device)\u001b[0m\n\u001b[1;32m     <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/utils/simulation.py?line=96'>97</a>\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[1;32m     <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/utils/simulation.py?line=97'>98</a>\u001b[0m     inpt_obsv, env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_simulation_input(seed, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/utils/simulation.py?line=98'>99</a>\u001b[0m     output_seq \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mforward(task_embedding\u001b[39m=\u001b[39;49minpt_obsv)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/utils/simulation.py?line=99'>100</a>\u001b[0m     critic_score \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39mget_critic_score(task_embedding\u001b[39m=\u001b[39minpt_obsv, last_seq\u001b[39m=\u001b[39moutput_seq, detach\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/utils/simulation.py?line=100'>101</a>\u001b[0m     success, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_outpt_fct(env\u001b[39m=\u001b[39menv, outpt\u001b[39m=\u001b[39moutput_seq, render\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/master_project/Code/MasterProject/model_src/../../MasterProject/model_src/model.py:112\u001b[0m, in \u001b[0;36mModel.optimize\u001b[0;34m(self, task_embedding)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/../../MasterProject/model_src/model.py?line=109'>110</a>\u001b[0m critic_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_loss_fct(critic_score\u001b[39m=\u001b[39mcritic_score, reward_label\u001b[39m=\u001b[39mreward_label)\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/../../MasterProject/model_src/model.py?line=110'>111</a>\u001b[0m \u001b[39mwhile\u001b[39;00m (step \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m epochs):\u001b[39m# and (best_expected_mean < threshold):\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/../../MasterProject/model_src/model.py?line=111'>112</a>\u001b[0m     critic_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/../../MasterProject/model_src/model.py?line=112'>113</a>\u001b[0m     trj_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='file:///home/hendrik/Documents/master_project/Code/MasterProject/model_src/../../MasterProject/model_src/model.py?line=114'>115</a>\u001b[0m     trj_optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/hendrik/anaconda3/envs/mujoco/lib/python3.8/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network.train(epochs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6edd83f9b3fcb9454c0e509bb1e55f01736f244b1bbba81ee1367549d9ea0fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mujoco')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
